{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comment cell\n",
    "\n",
    "# Uh-oh! The CEO wants more info (he's really needy). The CEO wants to know the following (for your regional store data only):\n",
    "\n",
    "# If a customer buys milk, does that imply the customer will buy cereal? And how confident are we in that?\n",
    "# If a customer does NOT buy milk, does that imply the customer will buy cereal? And how confident are we in that?\n",
    "# If a customer buys baby food, does that imply the customer will buy diapers? And how confident are we in that?\n",
    "# If a customer buys peanut butter, does that imply the customer will buy jelly or jam? And how confident are we in that?\n",
    "# If a customer does NOT buy peanut butter, does that imply the customer will buy jelly or jam? And how confident are we in that?\n",
    "# Sounds like a market basket analysis problem if I've ever heard one! Use the excel file in the homework module to get the CEO off your back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statments to use\n",
    "\n",
    "import sqlite3\n",
    "import csv \n",
    "import mlxtend\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first lets create the database and tables\n",
    "\n",
    "# Connect to SQLite database (or create if it doesn't exist)\n",
    "conn = sqlite3.connect('analysis.db')\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define SQL query to create table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS analysis (\n",
    "    last_name TEXT,\n",
    "    first_name TEXT,\n",
    "    cust_id INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query to create the table\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Read data from existing CSV file\n",
    "with open('southcentral.csv', 'r') as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "    for row in csv_reader:\n",
    "        # Insert data into SQLite table\n",
    "        cursor.execute(\"INSERT INTO analysis VALUES (?, ?, ?)\", (row['last_name'], row['first_name'], int(row['cust_id'])))\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create the jan_southcentral_purchases.csv file\n",
    "#first lets create the database and tables\n",
    "# Connect to SQLite database (or create if it doesn't exist)\n",
    "conn = sqlite3.connect('analysis.db')\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define SQL query to create table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS southcentral_purchases (\n",
    "    SKU INTEGER,\n",
    "    SalePrice INTEGER\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query to create the table\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Read data from existing CSV file\n",
    "with open('2024_jan_southcentral_purchases.csv', 'r') as csvfile:\n",
    "    csv_reader = csv.DictReader(csvfile)\n",
    "    for row in csv_reader:\n",
    "        # Insert data into SQLite table\n",
    "        cursor.execute(\"INSERT INTO southcentral_purchases VALUES (?, ?)\", (row['SKU'], row['SalePrice']))\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "# Connect to SQLite database (or create if it doesn't exist)\n",
    "conn = sqlite3.connect('analysis.db')\n",
    "\n",
    "# Create a cursor object to execute SQL queries\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define SQL query to create table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS products (\n",
    "    Manufacturer TEXT,\n",
    "    ProductName TEXT,\n",
    "    Size TEXT,\n",
    "    ItemType TEXT,\n",
    "    SKU INTEGER,\n",
    "    BasePrice REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query to create the table\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Read data from existing CSV file and insert into table\n",
    "with open('products.csv', 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip header row\n",
    "    for row in csv_reader:\n",
    "        cursor.execute(\"INSERT INTO products VALUES (?, ?, ?, ?, ?, ?)\", row)\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_13996\\2764200154.py:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  binary_data[binary_data != 0] = 1\n"
     ]
    }
   ],
   "source": [
    "# Read transaction data from CSV\n",
    "data = pd.read_csv('products.csv')\n",
    "# Perform one-hot encoding to convert categorical variables into binary indicators\n",
    "binary_data = pd.get_dummies(data)\n",
    "\n",
    "# Convert all non-zero values to 1 to represent presence\n",
    "binary_data[binary_data != 0] = 1\n",
    "\n",
    "# Optionally, you can drop any duplicate rows\n",
    "binary_data = binary_data.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Manufacturer        Product Name   Size       itemType       SKU BasePrice  \\\n",
      "0    Zatarains  Jambalaya Rice Mix  12 oz  Rice/Rice Mix  42081001     $2.49   \n",
      "1    Zatarains  Jambalaya Rice Mix  12 oz  Rice/Rice Mix  42081001     $2.49   \n",
      "2    Zatarains  Jambalaya Rice Mix  12 oz  Rice/Rice Mix  42081001     $2.49   \n",
      "3    Zatarains  Jambalaya Rice Mix  12 oz  Rice/Rice Mix  42081001     $2.49   \n",
      "4    Zatarains  Jambalaya Rice Mix  12 oz  Rice/Rice Mix  42081001     $2.49   \n",
      "\n",
      "   SalePrice  \n",
      "0       3.74  \n",
      "1       3.74  \n",
      "2       3.74  \n",
      "3       3.74  \n",
      "4       3.74  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file containing product information\n",
    "products_data = pd.read_csv('products.csv')\n",
    "\n",
    "# Load the second CSV file containing SKU and sale price\n",
    "sales_data = pd.read_csv('2024_jan_southcentral_purchases.csv')\n",
    "\n",
    "# Aggregate sales data by SKU\n",
    "sales_data_aggregated = sales_data.groupby('SKU').agg({'SalePrice': 'mean'}).reset_index()\n",
    "\n",
    "# Merge the aggregated sales data with the products data\n",
    "merged_data = pd.merge(products_data, sales_data_aggregated, on='SKU', how='inner')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Merge the two dataframes on the SKU column\n",
    "merged_data = pd.merge(products_data, sales_data, on='SKU', how='inner')\n",
    "\n",
    "# Display the merged data\n",
    "print(merged_data.head())\n",
    "\n",
    "merged_data.to_csv('merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged data from the CSV file\n",
    "merged_data = pd.read_csv('merged_data.csv')\n",
    "\n",
    "# Remove duplicate rows\n",
    "merged_data_no_duplicates = merged_data.drop_duplicates()\n",
    "\n",
    "# Save the DataFrame with no duplicates to a new CSV file\n",
    "merged_data_no_duplicates.to_csv('merged_data_no_duplicates.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a customer buys milk, does that imply the customer will buy cereal? False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfidence:\u001b[39m\u001b[38;5;124m\"\u001b[39m, confidence1)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Question 2: If a customer does NOT buy milk, does that imply the customer will buy cereal?\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m no_milk_to_cereal, confidence2 \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_association\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMilk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCereal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf a customer does NOT buy milk, does that imply the customer will buy cereal?\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m no_milk_to_cereal)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_milk_to_cereal:\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mcheck_association\u001b[1;34m(item1, item2)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_association\u001b[39m(item1, item2):\n\u001b[0;32m     28\u001b[0m     rules \u001b[38;5;241m=\u001b[39m get_association_rules(frequent_itemsets)\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, rule \u001b[38;5;129;01min\u001b[39;00m rules\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (rule[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mantecedents\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m({item1})) \u001b[38;5;129;01mand\u001b[39;00m (rule[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsequents\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m({item2})):\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m, rule[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[0;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[1;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[0;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:584\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    582\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m     manager \u001b[38;5;241m=\u001b[39m _get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m, silent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    587\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\construction.py:606\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    604\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 606\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    608\u001b[0m         object_index\n\u001b[0;32m    609\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[0;32m    610\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[0;32m    611\u001b[0m     ):\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[0;32m    613\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\dtypes\\cast.py:1190\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[1;32m-> 1190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[0;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[0;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[0;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_non_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM8[ns]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mlib.pyx:2543\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\core\\numeric.py:322\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, like)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;129m@set_array_function_like_doc\u001b[39m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;129m@set_module\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfull\u001b[39m(shape, fill_value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m, like\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    277\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;124;03m    Return a new array of given shape and type, filled with `fill_value`.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    320\u001b[0m \n\u001b[0;32m    321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlike\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _full_with_like(\n\u001b[0;32m    324\u001b[0m                 like, shape, fill_value, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules, apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load the merged data from the CSV file\n",
    "merged_data = pd.read_csv('merged_data_no_duplicates.csv')\n",
    "\n",
    "# Pivot the data to create a transactional format\n",
    "transactions = merged_data.pivot_table(index=['SKU', 'SalePrice'], columns='Product Name', aggfunc='size', fill_value=0)\n",
    "\n",
    "# Convert index to strings\n",
    "transactions.index = transactions.index.map(lambda x: '_'.join(map(str, x)))\n",
    "\n",
    "# Apply one-hot encoding to the data\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(df, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Define function to get association rules\n",
    "def get_association_rules(itemset, metric='confidence', min_threshold=0.5):\n",
    "    rules = association_rules(itemset, metric=metric, min_threshold=min_threshold)\n",
    "    return rules\n",
    "\n",
    "# Function to check association rules for given products\n",
    "def check_association(item1, item2):\n",
    "    rules = get_association_rules(frequent_itemsets)\n",
    "    for _, rule in rules.iterrows():\n",
    "        if (rule[\"antecedents\"] == frozenset({item1})) and (rule[\"consequents\"] == frozenset({item2})):\n",
    "            return True, rule[\"confidence\"]\n",
    "    return False, None\n",
    "\n",
    "# Question 1: If a customer buys milk, does that imply the customer will buy cereal?\n",
    "milk_to_cereal, confidence1 = check_association('Milk', 'Cereal')\n",
    "print(\"If a customer buys milk, does that imply the customer will buy cereal?\", milk_to_cereal)\n",
    "if milk_to_cereal:\n",
    "    print(\"Confidence:\", confidence1)\n",
    "\n",
    "# Question 2: If a customer does NOT buy milk, does that imply the customer will buy cereal?\n",
    "no_milk_to_cereal, confidence2 = check_association('Milk', 'Cereal')\n",
    "print(\"If a customer does NOT buy milk, does that imply the customer will buy cereal?\", not no_milk_to_cereal)\n",
    "if not no_milk_to_cereal:\n",
    "    print(\"Confidence:\", 1 - confidence2)\n",
    "\n",
    "# Question 3: If a customer buys baby food, does that imply the customer will buy diapers?\n",
    "baby_food_to_diapers, confidence3 = check_association('Baby Food', 'Diapers')\n",
    "print(\"If a customer buys baby food, does that imply the customer will buy diapers?\", baby_food_to_diapers)\n",
    "if baby_food_to_diapers:\n",
    "    print(\"Confidence:\", confidence3)\n",
    "\n",
    "# Question 4: If a customer buys peanut butter, does that imply the customer will buy jelly or jam?\n",
    "peanut_butter_to_jelly, confidence4 = check_association('Peanut Butter', 'Jelly')\n",
    "print(\"If a customer buys peanut butter, does that imply the customer will buy jelly?\", peanut_butter_to_jelly)\n",
    "if peanut_butter_to_jelly:\n",
    "    print(\"Confidence:\", confidence4)\n",
    "\n",
    "# Question 5: If a customer does NOT buy peanut butter, does that imply the customer will buy jelly or jam?\n",
    "no_peanut_butter_to_jelly, confidence5 = check_association('Peanut Butter', 'Jelly')\n",
    "print(\"If a customer does NOT buy peanut butter, does that imply the customer will buy jelly?\", not no_peanut_butter_to_jelly)\n",
    "if not no_peanut_butter_to_jelly:\n",
    "    print(\"Confidence:\", 1 - confidence5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
